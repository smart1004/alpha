{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 #파이썬 코드를 실행하기 전에 항상 모든 모듈을 Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P0', 'P8']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from posFARMlrn import posLearningScheduler\n",
    "posLearningScheduler.getServerStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['P0', 'P0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#============ Multi-GPU ==========\n",
    "from multi_gpu import to_multi_gpu\n",
    "posLearningScheduler.getServerStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 딥러닝 관련 Keras 라이브러리\n",
    "import keras\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "###### from keras.utils.training_utils import multi_gpu_model\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "# File I/O\n",
    "import subprocess\n",
    "import shutil\n",
    "import os, sys\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "# 데이터 처리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# 이미지 처리\n",
    "import cv2\n",
    "from scipy.ndimage import rotate\n",
    "import scipy.misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P0', 'P0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posLearningScheduler.getServerStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormpath4win32(in_path_filename):\n",
    "    #in_path_filename : '../input/train/c0\\\\img_14779.jpg'\n",
    "    #rs :  '../input/train/c0/img_14779.jpg'\n",
    "    if sys.platform == 'win32':\n",
    "        rs = in_path_filename.replace('\\\\','/')\n",
    "    else:\n",
    "        rs = in_path_filename\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args[1] = 'd/'                       # <- feather데이터 파일의 상대 경로\n",
    "# args[2] = 'datatest.feather'         # <- feather데이터 파일파일명\n",
    "# args[3] = 'test.log'                 # <- log 파일명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------\n",
    "# jupyter에서는 아래 명령이 안먹는다. (A10)\n",
    "#args = parser.parse_args()  #######  터미널 모드 적용 시 uncomment해야 함\n",
    "\n",
    "# 그래서(A10 의 사유로) 아래와 같이 변경함\n",
    "class ArgumentParser1():\n",
    "    pass\n",
    "args = ArgumentParser1()\n",
    "args.model = 'resnet50' # vgg16\n",
    "args.weights, args.learning_rate, args.semi_train =  None, 1e-4, None\n",
    "args.batch_size = 16 \n",
    "args.random_split = 1 \n",
    "args.data_augment  = 0 # data augment 1로 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('resnet50', None, 0.0001, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model, args.weights, args.learning_rate, args.semi_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_size = 2048\n",
    "n_class = 3\n",
    "seed = 10\n",
    "nfolds = 5\n",
    "test_nfolds = 3\n",
    "img_row_size, img_col_size = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_path = r'../input/train'\n",
    "train_path = r'./base_dir/train_dir'\n",
    "if args.semi_train is not None:\n",
    "    train_path = args.semi_train\n",
    "    args.semi_train = True\n",
    "# test_path = r'../input/test'\n",
    "test_path = r'./base_dir/test_dir'\n",
    "valid_path = r'./base_dir/valid_dir' #temp_valid_fold\n",
    "labels = ['c0', 'c1', 'c2']\n",
    "\n",
    "suffix = 'm{}.w{}.lr{}.s{}.nf{}.semi{}.b{}.row{}col{}.rsplit{}.augment{}.d{}'.format(args.model, args.weights, \n",
    "    args.learning_rate, seed, nfolds, args.semi_train, args.batch_size, img_row_size, img_col_size, args.random_split, \n",
    "    args.data_augment, datetime.now().strftime(\"%Y-%m-%d-%H-%M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp_train_fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_train_fold = r'../input/train_{}'.format(suffix)\n",
    "# temp_valid_fold = r'../input/valid_{}'.format(suffix)\n",
    "temp_train_fold = train_path\n",
    "temp_valid_fold = valid_path\n",
    "\n",
    "cache = r'../cache/{}'.format(suffix)\n",
    "subm = r'../subm/{}'.format(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clear_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "for path in [cache, subm]:\n",
    "    _clear_dir(path)    \n",
    "# for path in [temp_train_fold, temp_valid_fold, cache, subm]:\n",
    "#     _clear_dir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P0', 'P0']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posLearningScheduler.getServerStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #with K.tf.device('/device:CPU:0'):   #/device:CPU:0 https://3months.tistory.com/206\n",
    "    # 최상위 전결층을 제외한 모델을 불러온다\n",
    "    if args.weights == 'None':\n",
    "        args.weights = None\n",
    "    if args.model in ['vgg16']:\n",
    "        base_model = keras.applications.vgg16.VGG16(include_top=False, weights=args.weights, input_shape=(img_row_size, img_col_size,3))\n",
    "    elif args.model in ['vgg19']:\n",
    "        base_model = keras.applications.vgg19.VGG19(include_top=False, weights=args.weights, input_shape=(img_row_size, img_col_size,3))\n",
    "    elif args.model in ['resnet50']:\n",
    "        base_model = keras.applications.resnet50.ResNet50(include_top=False, weights=args.weights, input_shape=(img_row_size, img_col_size,3))\n",
    "    else:\n",
    "        print('# {} is not a valid value for \"--model\"'.format(args.model))\n",
    "        exit()\n",
    "\n",
    "    # 최상위 전결층을 정의한다\n",
    "    out = Flatten()(base_model.output)\n",
    "    out = Dense(fc_size, activation='relu')(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(fc_size, activation='relu')(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    output = Dense(n_class, activation='softmax')(out)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # https://3months.tistory.com/211?category=755917\n",
    "    # from keras.utils.training_utils import multi_gpu_model\n",
    "    #model = multi_gpu_model(model, gpus=2)  #@@@ gpu 2개\n",
    "    #============ Multi-GPU ============\n",
    "    model = to_multi_gpu(model,n_gpus=1)  #n_gpus=2\n",
    "    #===================================\n",
    "\n",
    "    # SGD Optimizer를 사용하여, 모델을 compile한다\n",
    "    sgd = SGD(lr=args.learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, cropx, cropy):\n",
    "    # 이미지 중간을 Crop하는 함수를 정의한다\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Model\n"
     ]
    }
   ],
   "source": [
    "def preprocess(image):\n",
    "    # rescale\n",
    "    image /= 255.\n",
    "\n",
    "    # rotate\n",
    "    rotate_angle = np.random.randint(40) - 20\n",
    "    image = rotate(image, rotate_angle)\n",
    "\n",
    "    # translate\n",
    "    rows, cols, _ = image.shape\n",
    "    width_translate = np.random.randint(60) - 30\n",
    "    height_translate = np.random.randint(60) - 30\n",
    "    M = np.float32([[1,0,width_translate],[0,1,height_translate]])\n",
    "    image = cv2.warpAffine(image,M,(cols,rows))\n",
    "    \n",
    "    # zoom\n",
    "    width_zoom = int(img_row_size * (0.8 + 0.2 * (1 - np.random.random())))\n",
    "    height_zoom = int(img_col_size * (0.8 + 0.2 * (1 - np.random.random())))\n",
    "    final_image = np.zeros((height_zoom, width_zoom, 3))\n",
    "    final_image[:,:,0] = crop_center(image[:,:,0], width_zoom, height_zoom)\n",
    "    final_image[:,:,1] = crop_center(image[:,:,1], width_zoom, height_zoom)\n",
    "    final_image[:,:,2] = crop_center(image[:,:,2], width_zoom, height_zoom)\n",
    "\n",
    "    # resize\n",
    "    image = cv2.resize(final_image, (img_row_size, img_col_size))\n",
    "    return image\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "print('# Train Model')\n",
    "# 이미지 데이터 전처리를 수행하는 함수를 정의한다\n",
    "# 실시간 전처리를 추가할 경우, 전처리 함수를 설정값에 넣어준다\n",
    "if args.data_augment:\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess)\n",
    "else:\n",
    "    #datagen = ImageDataGenerator()\n",
    "    datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_train_fold: ./base_dir/train_dir\n",
      "temp_valid_fold: ./base_dir/valid_dir\n",
      "test_path: ./base_dir/test_dir\n"
     ]
    }
   ],
   "source": [
    "print('temp_train_fold:', temp_train_fold)\n",
    "print('temp_valid_fold:', temp_valid_fold)\n",
    "print('test_path:', test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_split():\n",
    "    # 이미지 생성기를 위하여 임시 훈련/검증 폴더를 생성한다\n",
    "    def _generate_temp_folder(root_path):\n",
    "        #os.mkdir(root_path)\n",
    "        _clear_dir(root_path)\n",
    "        for i in range(n_class):\n",
    "            os.mkdir('{}/c{}'.format(root_path, i))\n",
    "    _generate_temp_folder(temp_train_fold)\n",
    "    _generate_temp_folder(temp_valid_fold)\n",
    "    \n",
    "    # 임시 훈련/검증 폴더에 데이터를 랜덤하게 복사한다\n",
    "    train_samples = 0\n",
    "    valid_samples = 0\n",
    "    for label in labels:\n",
    "        files = glob('{}/{}/*jpg'.format(train_path, label))\n",
    "        for fl in files:\n",
    "            cmd = 'cp {} {}/{}/{}'\n",
    "            if np.random.randint(nfolds) != 1:\n",
    "                # 데이터의 4/5를 훈련 데이터에 추가한다\n",
    "                cmd = cmd.format(fl, temp_train_fold, label, os.path.basename(fl))\n",
    "                train_samples += 1\n",
    "            else:\n",
    "                # 데이터의 1/5를 검증 데이터에 추가한다\n",
    "                cmd = cmd.format(fl, temp_valid_fold, label, os.path.basename(fl))\n",
    "                valid_samples += 1\n",
    "            # 원본 훈련 데이터를 임시 훈련/검증 데이터에 복사한다\n",
    "            subprocess.call(cmd, stderr=subprocess.STDOUT, shell=True)\n",
    "    # 훈련/검증 데이터 개수를 출력한다\n",
    "    print('# {} train samples | {} valid samples'.format(train_samples, valid_samples))\n",
    "    return train_samples, valid_samples            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_split99():\n",
    "    df_train = pd.read_csv('./base_dir/train_dir.csv') # encoding='euc-kr'\n",
    "    df_val = pd.read_csv('./base_dir/valid_dir.csv') # encoding='euc-kr'\n",
    "    df_test = pd.read_csv('./base_dir/test_dir.csv') # encoding='euc-kr'    \n",
    "    train_samples, valid_samples = len(df_train), len(df_val)\n",
    "    return train_samples, valid_samples   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6732 images belonging to 3 classes.\n",
      "Found 1772 images belonging to 3 classes.\n",
      "weight_path :  ../cache/mresnet50.wNone.lr0.0001.s10.nf5.semiNone.b16.row224col224.rsplit1.augment0.d2020-07-21-21-28/weight.fold_0.h5\n",
      "Epoch 1/10\n",
      "421/420 [==============================] - 166s 394ms/step - loss: 1.5706 - acc: 0.5295 - val_loss: 0.9911 - val_acc: 0.7049\n",
      "Epoch 2/10\n",
      "421/420 [==============================] - 151s 358ms/step - loss: 0.8628 - acc: 0.6592 - val_loss: 0.6788 - val_acc: 0.7387\n",
      "Epoch 3/10\n",
      "421/420 [==============================] - 151s 360ms/step - loss: 0.6794 - acc: 0.7362 - val_loss: 0.5369 - val_acc: 0.7940\n",
      "Epoch 4/10\n",
      "421/420 [==============================] - 151s 359ms/step - loss: 0.5646 - acc: 0.7732 - val_loss: 0.4939 - val_acc: 0.8042\n",
      "Epoch 5/10\n",
      "421/420 [==============================] - 151s 358ms/step - loss: 0.5299 - acc: 0.7862 - val_loss: 0.4112 - val_acc: 0.8352\n",
      "Epoch 6/10\n",
      "421/420 [==============================] - 151s 358ms/step - loss: 0.5075 - acc: 0.8028 - val_loss: 0.4032 - val_acc: 0.8431\n",
      "Epoch 7/10\n",
      "421/420 [==============================] - 152s 361ms/step - loss: 0.4834 - acc: 0.8036 - val_loss: 0.3906 - val_acc: 0.8465\n",
      "Epoch 8/10\n",
      "421/420 [==============================] - 151s 358ms/step - loss: 0.4723 - acc: 0.8189 - val_loss: 0.3821 - val_acc: 0.8386\n",
      "Epoch 9/10\n",
      "421/420 [==============================] - 151s 359ms/step - loss: 0.4515 - acc: 0.8206 - val_loss: 0.3703 - val_acc: 0.8527\n",
      "Epoch 10/10\n",
      "421/420 [==============================] - 151s 358ms/step - loss: 0.4528 - acc: 0.8203 - val_loss: 0.4929 - val_acc: 0.7895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5207ce1d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold=0 # kfold를 사용하지 않는다.\n",
    "# for fold in range(nfolds):\n",
    "# 새로운 모델을 정의한다\n",
    "model = get_model()\n",
    "\n",
    "# 훈련/검증 데이터를 생성한다\n",
    "train_samples, valid_samples = generate_split99()\n",
    "# 훈련/검증 데이터 생성기를 정의한다\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        directory=temp_train_fold,\n",
    "        target_size=(img_row_size, img_col_size),\n",
    "        batch_size=args.batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=seed)\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "        directory=temp_valid_fold,\n",
    "        target_size=(img_row_size, img_col_size),\n",
    "        batch_size=args.batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=seed)\n",
    "\n",
    "weight_path = '../cache/{}/weight.fold_{}.h5'.format(suffix, fold)\n",
    "print('weight_path : ', weight_path)\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "        ModelCheckpoint(weight_path, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "\n",
    "# 모델을 학습한다. val_loss 값이 3 epoch 연속 개악되면, 학습을 멈추고 최적 weight를 저장한다\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_samples/args.batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=valid_samples/args.batch_size,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 22 06:40:20 2020\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.strftime('%c', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_weights and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 날 아침, 다시 학습 시작\n",
      "Wed Jul 22 06:40:36 2020\n",
      "weight_path :  ../cache/mresnet50.wNone.lr0.0001.s10.nf5.semiNone.b16.row224col224.rsplit1.augment0.d2020-07-21-21-28/weight.fold_0.h5\n",
      "Epoch 1/5\n",
      "421/420 [==============================] - 152s 361ms/step - loss: 0.4290 - acc: 0.8348 - val_loss: 0.3421 - val_acc: 0.8679\n",
      "Epoch 2/5\n",
      "421/420 [==============================] - 152s 360ms/step - loss: 0.4152 - acc: 0.8347 - val_loss: 0.3968 - val_acc: 0.8493\n",
      "Epoch 3/5\n",
      "421/420 [==============================] - 150s 357ms/step - loss: 0.4126 - acc: 0.8383 - val_loss: 0.3495 - val_acc: 0.8674\n",
      "Epoch 4/5\n",
      "421/420 [==============================] - 151s 358ms/step - loss: 0.3925 - acc: 0.8415 - val_loss: 0.3321 - val_acc: 0.8612\n",
      "Epoch 5/5\n",
      "421/420 [==============================] - 151s 359ms/step - loss: 0.3771 - acc: 0.8497 - val_loss: 0.3407 - val_acc: 0.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4702ebb38>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"다음 날 아침, 다시 학습 시작\")\n",
    "print(time.strftime('%c', time.localtime(time.time())))\n",
    "\n",
    "epochs=5\n",
    "weight_path = '../cache/{}/weight.fold_{}.h5'.format(suffix, fold)\n",
    "print('weight_path : ', weight_path)\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "        ModelCheckpoint(weight_path, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "\n",
    "# 모델을 학습한다. val_loss 값이 3 epoch 연속 개악되면, 학습을 멈추고 최적 weight를 저장한다\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_samples/args.batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=valid_samples/args.batch_size,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>Label</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test_dir/c0</td>\n",
       "      <td>c0</td>\n",
       "      <td>1483104838__BBSFILEhealth07_1_.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test_dir/c0</td>\n",
       "      <td>c0</td>\n",
       "      <td>20130228_151608a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test_dir/c0</td>\n",
       "      <td>c0</td>\n",
       "      <td>7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test_dir/c0</td>\n",
       "      <td>c0</td>\n",
       "      <td>B9781416056638000033_f003_004_9781416056638_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test_dir/c0</td>\n",
       "      <td>c0</td>\n",
       "      <td>KakaoTalk_20200624_181118241_07.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Folder Label                                               File\n",
       "0  ./test_dir/c0    c0                 1483104838__BBSFILEhealth07_1_.jpg\n",
       "1  ./test_dir/c0    c0                               20130228_151608a.jpg\n",
       "2  ./test_dir/c0    c0    7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg\n",
       "3  ./test_dir/c0    c0  B9781416056638000033_f003_004_9781416056638_1_...\n",
       "4  ./test_dir/c0    c0                KakaoTalk_20200624_181118241_07.jpg"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./base_dir/test_dir.csv') # encoding='euc-kr'    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 테스트 데이터를 불러오는 ImageGenerator를 생성한다\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(img_row_size, img_col_size),\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "test_id = [os.path.basename(fl) for fl in glob('{}/imgs/*.jpg'.format(test_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path='../input/test/imgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 날 아침, 추가 학습 후 다시 test\n",
      "Wed Jul 22 07:01:07 2020\n",
      "Found 355 images.\n"
     ]
    }
   ],
   "source": [
    "print(\"다음 날 아침, 추가 학습 후 다시 test\")\n",
    "print(time.strftime('%c', time.localtime(time.time())))\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = datagen.flow_from_dataframe(\n",
    "                                dataframe = test_df.sort_values(by=\"Label\").reset_index(drop=True),\n",
    "                                directory = test_path,  # img_folder + \"/2ndSet_ThkConcat/\"\n",
    "                                x_col = \"File\",\n",
    "                                target_size = (img_row_size, img_col_size), # input_model.input_shape[1:3],  \n",
    "                                batch_size = 1,\n",
    "                                class_mode = None,\n",
    "                                shuffle = False)  \n",
    "test_gen.reset() \n",
    "#proba = model.predict_generator(test_gen, steps=len(test_gen.filenames))\n",
    "proba = model.predict_generator(test_gen, steps=len(test_gen.filenames))\n",
    "\n",
    "pred_lab = []\n",
    "for a_prob in proba :\n",
    "    pred_lab.append(labels[np.argmax(a_prob)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c0', 'c0', 'c0', 'c1']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_df = pd.DataFrame(proba, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'filename':test_gen.filenames, 'pred':pred_lab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>filename</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483104838__BBSFILEhealth07_1_.jpg</td>\n",
       "      <td>c0</td>\n",
       "      <td>1483104838__BBSFILEhealth07_1_.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20130228_151608a.jpg</td>\n",
       "      <td>c0</td>\n",
       "      <td>20130228_151608a.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg</td>\n",
       "      <td>c0</td>\n",
       "      <td>7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B9781416056638000033_f003_004_9781416056638_1_...</td>\n",
       "      <td>c0</td>\n",
       "      <td>B9781416056638000033_f003_004_9781416056638_1_...</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KakaoTalk_20200624_181118241_07.jpg</td>\n",
       "      <td>c0</td>\n",
       "      <td>KakaoTalk_20200624_181118241_07.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                File Label  \\\n",
       "0                 1483104838__BBSFILEhealth07_1_.jpg    c0   \n",
       "1                               20130228_151608a.jpg    c0   \n",
       "2    7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg    c0   \n",
       "3  B9781416056638000033_f003_004_9781416056638_1_...    c0   \n",
       "4                KakaoTalk_20200624_181118241_07.jpg    c0   \n",
       "\n",
       "                                            filename pred  \n",
       "0                 1483104838__BBSFILEhealth07_1_.jpg   c0  \n",
       "1                               20130228_151608a.jpg   c0  \n",
       "2    7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg   c0  \n",
       "3  B9781416056638000033_f003_004_9781416056638_1_...   c0  \n",
       "4                KakaoTalk_20200624_181118241_07.jpg   c0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f = pd.merge(test_df[[\"File\", \"Label\"]], pred_df, left_on=\"File\", right_on=\"filename\", how=\"left\")\n",
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>real</th>\n",
       "      <th>filename</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483104838__BBSFILEhealth07_1_.jpg</td>\n",
       "      <td>c0</td>\n",
       "      <td>1483104838__BBSFILEhealth07_1_.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20130228_151608a.jpg</td>\n",
       "      <td>c0</td>\n",
       "      <td>20130228_151608a.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg</td>\n",
       "      <td>c0</td>\n",
       "      <td>7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B9781416056638000033_f003_004_9781416056638_1_...</td>\n",
       "      <td>c0</td>\n",
       "      <td>B9781416056638000033_f003_004_9781416056638_1_...</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KakaoTalk_20200624_181118241_07.jpg</td>\n",
       "      <td>c0</td>\n",
       "      <td>KakaoTalk_20200624_181118241_07.jpg</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                File real  \\\n",
       "0                 1483104838__BBSFILEhealth07_1_.jpg   c0   \n",
       "1                               20130228_151608a.jpg   c0   \n",
       "2    7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg   c0   \n",
       "3  B9781416056638000033_f003_004_9781416056638_1_...   c0   \n",
       "4                KakaoTalk_20200624_181118241_07.jpg   c0   \n",
       "\n",
       "                                            filename pred  \n",
       "0                 1483104838__BBSFILEhealth07_1_.jpg   c0  \n",
       "1                               20130228_151608a.jpg   c0  \n",
       "2    7508b3dbe77877b262428cf687f7e9140c09d3ee_1_.jpg   c0  \n",
       "3  B9781416056638000033_f003_004_9781416056638_1_...   c0  \n",
       "4                KakaoTalk_20200624_181118241_07.jpg   c0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.rename(columns={\"Label\":\"real\"}, inplace=True)\n",
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8366197183098592"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy = accuracy_score(df_f[\"real\"], df_f[\"pred\"])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['c0', 'c1', 'c2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         c0       0.93      0.85      0.89       117\n",
      "         c1       0.89      0.80      0.84       120\n",
      "         c2       0.72      0.86      0.78       118\n",
      "\n",
      "avg / total       0.85      0.84      0.84       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_f[\"real\"], df_f[\"pred\"], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2208\n",
      "2245\n",
      "2280\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('train_dir/c0')))\n",
    "print(len(os.listdir('train_dir/c2')))\n",
    "print(len(os.listdir('train_dir/c1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581\n",
      "591\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('valid_dir/c0')))\n",
    "print(len(os.listdir('valid_dir/c2')))\n",
    "print(len(os.listdir('valid_dir/c1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "118\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('test_dir/c0')))\n",
    "print(len(os.listdir('test_dir/c2')))\n",
    "print(len(os.listdir('test_dir/c1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아래는 사용하지 않는다"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('# Ensemble')\n",
    "# 5-Fold 교차 검증의 결과물을 단순 앙상블한다\n",
    "ensemble = 0\n",
    "for fold in range(nfolds):\n",
    "    ensemble += pd.read_csv('../subm/{}/f{}.csv'.format(suffix, fold), index_col=-1).values * 1. / nfolds\n",
    "ensemble = pd.DataFrame(ensemble, columns=labels)\n",
    "ensemble.loc[:, 'img'] = pd.Series(test_id, index=ensemble.index)\n",
    "sub_file = '../subm/{}/ens.csv'.format(suffix)\n",
    "ensemble.to_csv(sub_file, index=False)\n",
    "\n",
    "print('*'*60)\n",
    "print('# It is done')\n",
    "\n",
    "# 캐글에 제출한다\n",
    "# submit_cmd = 'kaggle competitions submit -c state-farm-distracted-driver-detection -f {} -m {}'.format(sub_file, suffix)\n",
    "# subprocess.call(submit_cmd, stderr=subprocess.STDOUT, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
